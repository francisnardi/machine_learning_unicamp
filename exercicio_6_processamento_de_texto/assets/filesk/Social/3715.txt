twitter today announced some product policy changes aimed better tackling violent threats abuse platform
the problem mainstre social network misappropriated as amplification medium for minority hate groups  instance  spread jihadist terrorist sentiments propaganda harass threaten women messages of violent misogyny risen political agenda recent times especially given spread isis middle east
away terrorism gamergate saga rebounded on twitter as women involved games industry its platform turned into a conduit violently misogynistic and sustained online harassment included death rape threats graphic material doxxing
and that means exception various public figures (female male suffered episodes of abuse via the platform recent years british journalist feminist activist caroline criado perez (following her  campaign woman depicted british bank notes daughter robin williams following father suicide the sight public figure taking twitter hiatus abusive episode regular occurrence
just month comedian sue perkins tweeted twitter bit targeted violent death threats following rumors presenter bbc tv cars
back february leaked memo twitter ceo dick costolo staff indicated he was aware twitter abuse problem intending (finally prioritizing tackling it we suck dealing abuse trolls platform we’ve sucked years it secret rest world talks day lose core user core user addressing simple trolling issues face day wrote
to use vernacular shit
today twitter laid latest strategies for dealing abusive trolling are still evidently work progress twitter suggests entire precarious business balancing long stated desire to champion free speech need avoid becoming a dumb conduit for online bullying (and worse is likely result continued tweaks area
as ultimate goal ensure twitter safe place widest possible range perspectives continue evaluate update approach critical arena notes shreyas doshi twitter director product management
one key change twitter announced today described test clearly actively evaluated effectiveness this actual product change just policy tweak (though it doing tweaking too
we begun test product feature help identify suspected abusive tweets limit reach writes doshi describing amounts pre emptive filtering tweets  in bid identify limit spread abusive content platform
so words cut abusive trolls moment of tweeting targeted abuse has hit home caused intended distress pretty big step company bullish pronouncing ‘tweets flow’ past
this feature takes account wide range signals context frequently correlates abuse including age account similarity tweet content safety te past independently determined  abusive adds doshi
it affect ability content you’ve explicitly sought tweets accounts follow  instead designed help limit potential harm abusive content feature does account content posted followed user controversial unpopular
the guardian reports new (let say beta abuse filter being based optional quality filter available verified twitter users  ‘tailored’ notifications option highlighted  albeit as strict as the verified filter which given anti abuse filter automatically users just optional toggle makes sense

twitter is making two policy changes aimed tightening screw violent threats widening said unduly narrow definition threats before  sounds like aimed tackling terrorist propaganda spread twitter
we updating violent threats policy prohibition limited direct specific threats violence  extends threats violence promoting violence previous policy unduly narrow limited ability act certain kinds threatening behavior updated language better describes range prohibited content intention act users step line abuse writes doshi
twitter is tweaking enforcement actions dealing abuse violations  adding new option (in addition existing ones require users delete content verify phone number gives support te ability lock abusive accounts specific periods time throttle velocity trolling episodes locking abuses accounts
this option gives leverage variety contexts particularly multiple users begin harassing particular person group people  adds doshi
many people received abuse twitter included observed trolling often follows pattern  sustained wave harassment directed target over relatively compact time period appears been redirected twitter online platform (presumably original troll was posted twitter temporarily lock accounts mass trolling events taking place a potential way defang defuse ordinated bullying campaign ( abusers create new accounts restart abuse
while dedicating resources better responding abuse reports necessary critical equally important priority identifying limiting incentives enable encourage users engage abuse adds doshi
twitter doing outreach online misogyny november it heard evidence te academics affiliated with lancaster university researching online misogyny rape threats using twitter research project started november  the discourses online misogyny (doom te aiming to develop methods tools analyzing online hate speech building linguistic profiles abusers identifying community specific lexis order aid automating detection online abuse abusers looks likely twitter drawing that research here
discussing doom project work november focused specifically twitter data relating criado perez abuse case researcher mark mcglashan said te had combined linguistic analysis social network analysis look people affiliate via language create communities use discourse way forms groups trolls deliberate join together to abuse people online
what need build profiles kind language use community specific language told techcrunch time does look like community specific languages  like misspellings rape… ‘raep’ ‘raep crew’… definitely group markers community specific lexis that use
if incidents occurs occurs quite frequently build dataset profile automatically detect people abusive similar way… the methodology i’ve come pretty automated come profile detect automatically far off
you crossover misogyny homophobia misogyny racism antisemitism… so group kind language using homophobia racism sexism misogyny mcglashan added
another recent piece research antisocial behavior online coming cornell stanford universities looks promising algorithmically defeating trolls research suggests future trolling behavior ends severe user banned online community  predicted advance analyzing just handful (five  posts the researchers say analysis able predict  accuracy user would  subsequently banned
