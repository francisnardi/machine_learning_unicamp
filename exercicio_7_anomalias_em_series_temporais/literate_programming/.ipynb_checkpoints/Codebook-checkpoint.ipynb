{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Titulo:** Exercício 7 - Deteção de anomalias em séries temporais <br>\n",
    "**Autor:** Juan Sebastián Beleño Díaz <br>\n",
    "**Data:** 21 de Novembro de 2016 <br>\n",
    "\n",
    "## Introdução\n",
    "Neste trabalho vai ser apresentado um algoritmo de deteção de anomalias em séries temporais baseado em média e desvio padrão. Além disso, vou apresentar um algoritmo para selecionar o tamanho dos trechos nas séries temporais.\n",
    "\n",
    "## Dados\n",
    "Os arquivos usados neste trabalho são séries temporais com diferentes anomalias: [série temporal 1](http://www.ic.unicamp.br/~wainer/cursos/2s2016/ml/serie1.csv), [série temporal 2](http://www.ic.unicamp.br/~wainer/cursos/2s2016/ml/serie2.csv), [série temporal 3](http://www.ic.unicamp.br/~wainer/cursos/2s2016/ml/serie3.csv), [série temporal 4](http://www.ic.unicamp.br/~wainer/cursos/2s2016/ml/serie4.csv). Finalmente, o algoritmo apresentado tem que ser implementado na deteção de anomalias na [série temporal 5](http://www.ic.unicamp.br/~wainer/cursos/2s2016/ml/serie5.csv). Todos os arquivos tem duas colunas, uma com o *timestamp* e a outra com o *value*. No entanto, este trabalho vai usar o índice invés do *timestamp*.\n",
    "\n",
    "## Preparação dos dados\n",
    "Antes de começar trablahar com os dados é preciso incluir as dependecias do projeto:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Loading the libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem muitas maneiras de abrir os arquivos e obter os dados, mas neste caso foi usado pandas para obter os dataframes diretamente desde a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_serie_1 = 'http://www.ic.unicamp.br/~wainer/cursos/2s2016/ml/serie1.csv'\n",
    "url_serie_2 = 'http://www.ic.unicamp.br/~wainer/cursos/2s2016/ml/serie2.csv'\n",
    "url_serie_3 = 'http://www.ic.unicamp.br/~wainer/cursos/2s2016/ml/serie3.csv'\n",
    "url_serie_4 = 'http://www.ic.unicamp.br/~wainer/cursos/2s2016/ml/serie4.csv'\n",
    "url_serie_5 = 'http://www.ic.unicamp.br/~wainer/cursos/2s2016/ml/serie5.csv'\n",
    "\n",
    "df_serie_1 = pd.read_csv(url_serie_1, header= 0)\n",
    "df_serie_2 = pd.read_csv(url_serie_2, header= 0)\n",
    "df_serie_3 = pd.read_csv(url_serie_3, header= 0)\n",
    "df_serie_4 = pd.read_csv(url_serie_4, header= 0)\n",
    "df_serie_5 = pd.read_csv(url_serie_5, header= 0)\n",
    "\n",
    "# Selecting the time series without timestamp\n",
    "ts1 = np.ravel(df_serie_1['value'])\n",
    "ts2 = np.ravel(df_serie_2['value'])\n",
    "ts3 = np.ravel(df_serie_3['value'])\n",
    "ts4 = np.ravel(df_serie_4['value'])\n",
    "ts5 = np.ravel(df_serie_5['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vetor descritor\n",
    "Neste trabalho vou usar um descritor composto de um vetor de [média, desvio padrão] para o trecho da série temporal. Cada trecho tem uma superposição de (N - 1) pontos em trechos vizinhos, em que N é o tamanho do trecho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates the descriptor (mean, standard deviation)\n",
    "# ts: a vector of Time Series\n",
    "# N: the length of the subsequence considered\n",
    "def get_descriptor(ts, N):\n",
    "    \n",
    "    mean = []\n",
    "    std = []\n",
    "    M = len(ts)\n",
    "    \n",
    "    for i in range(0, M - N + 1 ):\n",
    "        mean.append(np.mean(ts[i:i + N]))\n",
    "        std.append(np.std(ts[i:i + N]))        \n",
    "        \n",
    "    return[mean, std]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de deteção de anomalias\n",
    "O algoritmo apresentado neste trabalho para a deteção de anomalias basea-se no suposto de uma distribuição normal em cada trecho da série temporal. Portanto, um trecho **A** é similar a outro trecho **B** se a média do trecho **B** está no intervalo da média do trecho **A** mais ou menos o desvio padrão de **A**. O algoritmo utiliza um vetor para contar o número de trechos similares a cada trecho. O valor mínimo do vetor é uma anomalia porque tem menos similaridade com outro trechos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Matches each descriptor against others to find similarities based on\n",
    "# pertecentage, i.e. for each descriptor we assume that there is a similarity \n",
    "# if the mean and stardard deviation does not change more than a percentage\n",
    "# compared with other descriptor. Finally, we count the number of similar \n",
    "# descriptors and those with less similarities are anomalies\n",
    "def match_descriptors(mean, std, p_limit = 2):\n",
    "    \n",
    "    K = len(mean)\n",
    "    match_vector = []\n",
    "    \n",
    "    for i in range(0, K):\n",
    "        counter = 0\n",
    "        for j in range(0, K):\n",
    "            p_mean = 0\n",
    "            p_std = 0\n",
    "            \n",
    "            # I'm assming a gaussian distribution here\n",
    "            # p_limit = 2 => 95% of confidence\n",
    "            if(mean[j] <= (mean[i] + std[i] * p_limit) and mean[j] >= (mean[i] - std[i] * p_limit)):\n",
    "                counter = counter + 1\n",
    "            \n",
    "                \n",
    "        match_vector.append(counter)\n",
    "    \n",
    "    return match_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de cálculo do tamanho dos trechos\n",
    "O algoritmo apresentado nesta seção faz dois vetores diferentes, um para medir o número de pontos consecutivos que tem valor acima da média da série temporal e o outro para medir o número de pontos consecutivos que tem valor abaixo da média da série temporal. O máximo valor dos trecho dos dois vetores é calculado e o tamanho do trecho pode ser o máximo do vetor de valores acima da média ou a diferença entre o valor máximo do vetor de valores abaixo da média e o máximo do vetor de valores acima da média."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function finds the size of the subsequence in the time series,\n",
    "# counting the number of points in sequence above the mean, and also counting\n",
    "# the number of points in sequence below the mean. We calculate the max \n",
    "# sequence for points above and below the mean and based on that we \n",
    "# choose the max sequence above or the substraction between max sequence\n",
    "# below and max sequence above.\n",
    "def find_N(ts):\n",
    "    \n",
    "    mean = np.mean(ts)\n",
    "    subseq_up_arr = []\n",
    "    subseq_down_arr = []\n",
    "    subseq_up_length = 0\n",
    "    subseq_down_length = 0\n",
    "\n",
    "    for value in ts:\n",
    "        if value > mean:\n",
    "            subseq_up_length = subseq_up_length + 1\n",
    "            if subseq_down_length > 0:\n",
    "                subseq_down_arr.append(subseq_down_length)\n",
    "                subseq_down_length = 0\n",
    "        else:\n",
    "            subseq_down_length = subseq_down_length + 1\n",
    "            if subseq_up_length > 0:\n",
    "                subseq_up_arr.append(subseq_up_length)\n",
    "                subseq_up_length = 0\n",
    "    \n",
    "    subseq_up_max = np.amax(subseq_up_arr)\n",
    "    subseq_down_max = np.amax(subseq_down_arr)\n",
    "    subseq_relationship = subseq_down_max / subseq_up_max\n",
    "    wavelength = 0\n",
    "    \n",
    "    if(subseq_relationship > 3  and subseq_relationship < 5):\n",
    "        wavelength = subseq_down_max - subseq_up_max\n",
    "    else:\n",
    "        wavelength = subseq_up_max\n",
    "        \n",
    "    \n",
    "    return wavelength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validando o algoritmo\n",
    "Primeiro é feito um algoritmo para diminuir o conjunto de linhas de código para gerar as imagens e os resultados da validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Takes the time serie and find a wavelength to execute an anomaly detection\n",
    "# Finally, it plots the time serie and the anomaly\n",
    "def show_anomaly(ts):\n",
    "    \n",
    "    ts_length = len(ts)\n",
    "    wavelength = math.floor(find_N(ts))\n",
    "\n",
    "    descriptor = get_descriptor(ts, wavelength)\n",
    "    mean = descriptor[0]\n",
    "    std = descriptor[1]\n",
    "\n",
    "    match_descriptor = match_descriptors(mean, std)\n",
    "    anomaly_index = np.argmin(match_descriptor)\n",
    "    \n",
    "    # This is hacky just to make visible the anomaly in the pĺot\n",
    "    # because in some case the anomaly size is so little it can't be\n",
    "    # plotted\n",
    "    if(wavelength < 10):\n",
    "        wavelength = 10\n",
    "    \n",
    "    fig_width = 16\n",
    "    fig_height = 8\n",
    "    fig_dpi = 100\n",
    "    plt.figure(figsize=(fig_width, fig_height), dpi=fig_dpi)\n",
    "    \n",
    "    plt.plot(range(0,ts_length), ts, '#ff5722', \n",
    "             range(anomaly_index,(anomaly_index + wavelength)),\n",
    "             ts[range(anomaly_index,(anomaly_index + wavelength))],\n",
    "             '#009688')\n",
    "    plt.ylabel('Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, o algoritmo é validado usando todas as séries temporais e plotando os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_anomaly(ts1)\n",
    "show_anomaly(ts2)\n",
    "show_anomaly(ts3)\n",
    "show_anomaly(ts4)\n",
    "show_anomaly(ts5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
