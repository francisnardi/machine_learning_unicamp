{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Titulo:** Exercício 5 - Desafio de regressores <br>\n",
    "**Autor:** Juan Sebastián Beleño Díaz <br>\n",
    "**Data:** 8 de Novembro de 2016 <br>\n",
    "\n",
    "## Introdução\n",
    "Neste trabalho é feita uma comparação entre dois regressores (Gradient Boosting Regression e Random Forest Regression)usando a métrica de Mean Absolute Error (MAE). Todos os regressores usam optimização de hiperpârametros e validação externa. Finalmente, o melhor regressor é usado sobre os dados de teste para achar o valor de regressão, que será avaliado com a métrica MAE pelo professor Jaques Wainer.\n",
    "\n",
    "## Dados\n",
    "Os arquivos utilizados neste trabalho são os [dados de treino](http://www.ic.unicamp.br/%7Ewainer/cursos/2s2016/ml/train.csv) e os [dados de teste](http://www.ic.unicamp.br/%7Ewainer/cursos/2s2016/ml/test.csv). A primeira coluna dos dados de treino são os dados a serem calculados pelo regressor. O arquivo do conjunto de teste não tem o valor de regressão e deve ser calculado.\n",
    "\n",
    "## Preparação dos dados\n",
    "Antes de começar trablahar com os dados é preciso incluir as dependecias do projeto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem muitas maneiras de abrir os arquivos e obter os dados, mas neste caso foi usado *pandas* para obter os dataframes diretamente desde a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file = '../results/values_test.csv'\n",
    "\n",
    "# Defining the URIs with raw data\n",
    "url_train_data = 'http://www.ic.unicamp.br/%7Ewainer/cursos/2s2016/ml/train.csv'\n",
    "url_test_data = 'http://www.ic.unicamp.br/%7Ewainer/cursos/2s2016/ml/test.csv'\n",
    "\n",
    "# Reading the files with the raw data\n",
    "df_train = pd.read_csv(url_train_data, header = None, delimiter = \",\")\n",
    "df_test = pd.read_csv(url_test_data, header = None, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento dos dados\n",
    "O pré-processamento é utilizado para melhorar a precisão dos regressores. Neste projeto foram tranformados os dados categóricos em dados numéricos e não foi executado um PCA sobre os dados porque foi considerado que possívelmente isto podería dificultar o trabalho dos regressores. No entanto, é possível eliminar os dados com pouca variância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a label encoders to handle categorical data\n",
    "categorical_attributes = [4,5,6,7,8,9,11,12,15,16,17,20,22,28,29,30]\n",
    "general_le = []\n",
    "invert_index_le = 0\n",
    "general_le_test = []\n",
    "invert_index_le_test = 0\n",
    "\n",
    "train_params = df_train.iloc[:, 1:33]\n",
    "train_values = np.ravel(df_train.iloc[:, 1:2])\n",
    "\n",
    "df_train_with_numbers = df_train\n",
    "df_test_with_numbers = df_test\n",
    "\n",
    "# Training set\n",
    "for i in categorical_attributes:\n",
    "    general_le.append(preprocessing.LabelEncoder())\n",
    "    df_train_with_numbers[i] = general_le[invert_index_le].fit_transform(df_train_with_numbers[i])\n",
    "    invert_index_le = invert_index_le + 1\n",
    "    \n",
    "train_params_with_numbers = df_train_with_numbers.iloc[:, 1:33]\n",
    "\n",
    "# Test set\n",
    "for i in categorical_attributes:\n",
    "    general_le_test.append(preprocessing.LabelEncoder())\n",
    "    df_test_with_numbers[i-1] = general_le_test[invert_index_le_test].fit_transform(df_test_with_numbers[i-1])\n",
    "    invert_index_le_test = invert_index_le_test + 1\n",
    "    \n",
    "test_params_with_numbers = df_test_with_numbers\n",
    "    \n",
    "\n",
    "# Number of columns and rows in the train data\n",
    "n_columns = df_train.shape[1] # 33\n",
    "n_rows = df_train.shape[0] # 9000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros\n",
    "De maneira geral é definido um conjunto de variáveis que serão utilizadas para achar os melhores hiperparâmetros dos regressores. Além disso, é definido o número de splits na *cross-validation*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of splits for internal and external cross validation\n",
    "n_internal_folds = 3\n",
    "n_external_folds = 3\n",
    "\n",
    "# Random Forest\n",
    "best_external_n_estimators = 64\n",
    "best_external_mae_rf = 1.0\n",
    "\n",
    "# Gradient Boosting Descent\n",
    "best_external_n_trees = 100\n",
    "best_learning_rate = 0.1\n",
    "best_external_mae_gbm = 1.0\n",
    "\n",
    "# WARNING: I work with an i5 with 4 cores 3.3.GHz, please adjust this parameter\n",
    "# to the number of cores your processor have\n",
    "n_jobs = 4\n",
    "pre_dispatch = 6 # 2 * n_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressores\n",
    "Os regressores escolhidos foram o Gradient Boosting Regressor e Random Forest Regressor porque eles trabalham bem com dados categóricos. No entanto, eles precisam de um tempo maior de processamento e mais memória por ser *ensembles*. A optimização de hiperparâmetros foi feita manualmente porque o pacote *GridSearchCV* de *sklearn* utiliza muita memória para o caso de regressores. 12GB de RAM não foram suficiêntes para executar um gridSearch com 3 cross-validation num conjunto de dados de 9000 filas e 33 colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_model(train_params, test_params, train_values, test_values):\n",
    "    \n",
    "    # [1] Oshiro, Thais Mayumi, Pedro Santoro Perez, and José Augusto Baranauskas. \n",
    "    # \"How many trees in a random forest?.\" International Workshop on Machine \n",
    "    # Learning and Data Mining in Pattern Recognition. Springer Berlin Heidelberg, 2012.\n",
    "    # Between 64 and 128 trees\n",
    "    n_estimators_array = range(64,129, 8)\n",
    "    best_n_estimators = 64\n",
    "    best_mae = 1.0\n",
    "\n",
    "    for n_estimators in n_estimators_array:\n",
    "        \n",
    "        regressor = RandomForestRegressor(n_estimators = n_estimators,\n",
    "                                          criterion = 'mae',\n",
    "                                          n_jobs = n_jobs)\n",
    "        regressor.fit(train_params, train_values)\n",
    "\n",
    "        model_predictions = regressor.predict(test_params)\n",
    "        mae = mean_absolute_error(test_values, model_predictions)\n",
    "\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_n_estimators = n_estimators\n",
    "    \n",
    "    return [best_mae, best_n_estimators]\n",
    "\n",
    "\n",
    "def gbm_model(train_params, test_params, train_values, test_values):\n",
    "    \n",
    "    learning_rate_array = [0.1, 0.05]\n",
    "    n_trees_array = [100, 125, 150]\n",
    "    \n",
    "    best_learning_rate = 0.1\n",
    "    best_n_trees = 100\n",
    "    best_mae = 1.0\n",
    "\n",
    "    for learning_rate in learning_rate_array:\n",
    "        for n_trees in n_trees_array:\n",
    "            \n",
    "            regressor = GradientBoostingRegressor(n_estimators = n_trees,\n",
    "                                                  criterion = 'mae',\n",
    "                                                  learning_rate = learning_rate)\n",
    "            regressor.fit(train_params, train_values)\n",
    "\n",
    "            model_predictions = regressor.predict(test_params)\n",
    "            mae = mean_absolute_error(test_values, model_predictions)\n",
    "\n",
    "            if mae < best_mae:\n",
    "                best_mae = mae\n",
    "                best_n_trees = n_trees\n",
    "                best_learning_rate = learning_rate\n",
    "    \n",
    "    return [best_mae, best_n_trees,best_learning_rate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização de hiperparâmetros\n",
    "A otimização dos hiperparâmetros usa uma cross validação externa de 3 folds para os regressores, obtendo também a métrica MAE para cada um deles. Ao final do loop for são obtidos os hiperparâmetros dos regressores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ------------------------ Here Goes the Magic -------------------------------\n",
    "\n",
    "# Define the external K-Fold Stratified\n",
    "external_skf = StratifiedKFold(n_splits = n_external_folds)\n",
    "external_skf.get_n_splits(train_params, train_values) \n",
    "\n",
    "# Iterate over external data\n",
    "for external_train_index, external_test_index in external_skf.split(train_params, train_values):\n",
    "    \n",
    "    # Split the external training set and the external test set\n",
    "    external_params_train = train_params.iloc[external_train_index, :]\n",
    "    external_params_train_with_numbers = train_params_with_numbers.iloc[external_train_index, :]\n",
    "    external_classes_train = train_values[external_train_index] \n",
    "    external_params_test = train_params.iloc[external_test_index, :]\n",
    "    external_params_test_with_numbers = train_params_with_numbers.iloc[external_test_index, :]\n",
    "    external_classes_test = train_values[external_test_index]\n",
    "    \n",
    "    # Random Forest Regressor\n",
    "    rf_array = rf_model(external_params_train_with_numbers, \n",
    "                        external_params_test_with_numbers, \n",
    "                        external_classes_train, \n",
    "                        external_classes_test)\n",
    "\n",
    "    # Using external cross-validation to find the best hyperparameter for RF\n",
    "    if rf_array[0] < best_external_mae_rf:\n",
    "        best_external_mae_rf = rf_array[0]\n",
    "        best_external_n_estimators = rf_array[1]\n",
    "        \n",
    "    # Gradient  Boosting Descent\n",
    "    gbm_array = gbm_model(external_params_train_with_numbers, \n",
    "                          external_params_test_with_numbers, \n",
    "                          external_classes_train, \n",
    "                          external_classes_test)\n",
    "                          \n",
    "    # Using external cross-validation to fin best hyperparameters for GBM\n",
    "    if gbm_array[0] < best_external_mae_gbm:\n",
    "        best_external_mae_gbm = gbm_array[0]\n",
    "        best_external_n_trees = gbm_array[1]\n",
    "        best_learning_rate = gbm_array[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "O Random Forest Regressor foi o melhor regressor para este conjunto de dados com um MAE = 0.0 ou precisão perfeita. Os hiperparâmetros otimizados para o RF Regressor são n_estimators = 64. Provávelmente este regressor tem *overfitting* sobre os dados de treinamento. No entanto, ele é usado para calcular o resultado para os dados de teste e o professor será quem avalie a precisão do meu regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "# of estimators:  64\n",
      "MAE:  0.0\n",
      "---------------------------------\n",
      "Gradient Boosting Descent\n",
      "# of estimators:  150\n",
      "Learning rate:  0.1\n",
      "MAE:  7.37929825042e-05\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest')\n",
    "print('# of estimators: ', best_external_n_estimators)\n",
    "print('MAE: ', best_external_mae_rf)\n",
    "print(\"---------------------------------\")\n",
    "print('Gradient Boosting Descent')\n",
    "print('# of estimators: ', best_external_n_trees)\n",
    "print('Learning rate: ', best_learning_rate)\n",
    "print('MAE: ', best_external_mae_gbm)\n",
    "print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão dos dados de teste\n",
    "O Random Forest Regressor com os hiperparâmetros otimizados cálcula os valores para o conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators = best_external_n_estimators,\n",
    "                                  criterion = 'mae',\n",
    "                                  n_jobs = n_jobs)\n",
    "regressor.fit(train_params_with_numbers, train_values)\n",
    "value_predictions = regressor.predict(test_params_with_numbers)\n",
    "\n",
    "df_predictions = pd.DataFrame(value_predictions)\n",
    "df_predictions.to_csv(output_file, sep=',', encoding='utf-8', header = False, index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
