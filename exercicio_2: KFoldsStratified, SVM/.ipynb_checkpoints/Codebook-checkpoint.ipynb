{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Titulo:** Exercício 2 - Grid Search, Stratified K-Folds e SVM <br>\n",
    "**Autor:** Juan Sebastián Beleño Díaz <br>\n",
    "**Data:** 3 de Outubro de 2016 <br>\n",
    "\n",
    "## Introdução\n",
    "Neste trabalho é achado os valores optimizados de gamma e C=1/alpha para um SVM com kernel RBF, usando K-folds estratificados externos para achar a acurácia do SVM e K-Folds estratificados internos para achar os hiperparâmetros gamma e C. \n",
    "\n",
    "## Dados\n",
    "O arquivo base deste trabalho é [data1.csv](http://www.ic.unicamp.br/~wainer/cursos/2s2016/ml/data1.csv); o arquivo contém 167 colunas e 476 filas. As primeiras 166 colunas do conjunto de dados tem um nome f{n} onde n é um número incremental desde 1 até 166; a coluna 167 é a clase à que pertence cada fila.\n",
    "\n",
    "## Preparação dos dados\n",
    "Antes de começar a trablahar com os dados é preciso incluir as dependecias do projeto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem muitas maneiras de abrir o arquivo csv e obter os dados, mas neste caso vamos usar pandas para obter o dataframe diretamente desde a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading the csv file with the raw data\n",
    "df = pd.read_csv('http://www.ic.unicamp.br/~wainer/cursos/2s2016/ml/data1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar os dados para obter os parâmetros e os resultados ou classes dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ncolumns = df.shape[1] # 167 columns\n",
    "ncolumns_without_class = ncolumns - 1 # 166 columns\n",
    "\n",
    "# Removing the column 'clase' from the dataset\n",
    "df_params = df.iloc[:, 0:ncolumns_without_class]\n",
    "\n",
    "# Getting the column 'clase' from the dataset\n",
    "df_result = df.iloc[:,ncolumns_without_class:ncolumns]\n",
    "df_result = np.ravel(df_result) # convert a column vector to vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir um conjunto de variáveis que vão ser usadas depois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare important variables to use later\n",
    "n_external_folds = 5\n",
    "n_internal_folds = 3\n",
    "\n",
    "gamma_values_set = [2**-15, 2**-10, 2**-5, 2**0, 2**5]\n",
    "c_values_set = [2**-5, 2**-2, 2**0, 2**2, 2**5]\n",
    "optimal_gamma = 0\n",
    "optimal_c = 0\n",
    "\n",
    "final_accuracy = 0\n",
    "best_accuracy = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento dos dados\n",
    "Implementamos um K-Fold estratificado externo de 5 folds para separar conjuntos de treino e conjunto de testes, achando assim o valor médio da acurácia esperada de um SVM com kernel RBF em cada fold. Além disso, é implementado um K-fold interno com 3 folds para cada fold externo, achando os melhores valores de gamma e C, iterando sobre conjunto fixos de dados. O valor do C itera sobre valores contidos no array [2^-5, 2^-2, 2^0, 2^2, 2^5]. O valor do gamma itera sobre os valores contidos no array [2^-15, 2^-10, 2^-5, 2^0, 2^5]. Os valores finais de gamma e C correspondem à maior acurácia obtida nos folds internos. Para calcular a acurácia de cada fold é usado um SVM com kernel RBF que trabalha com validação interna dentro dos dados externos de treino. A acurácia de cada fold é somada a variável *final_accuracy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the external K-Fold Stratified\n",
    "external_skf = StratifiedKFold(df_result, n_folds = n_external_folds)\n",
    "\n",
    "# Iterate over several folds to find a good accuracy in the SVM \n",
    "for external_train_index, external_test_index in external_skf:\n",
    "    \n",
    "    # Declare external variables\n",
    "    external_accuracy = 0\n",
    "    external_gamma_value = 0\n",
    "    external_c_value = 0\n",
    "    \n",
    "    # Split the external training set and the external test set\n",
    "    external_params_train = df_params.iloc[external_train_index, :] \n",
    "    external_results_train = df_result[external_train_index] \n",
    "    external_params_test = df_params.iloc[external_test_index, :]\n",
    "    external_results_test = df_result[external_test_index]\n",
    "    \n",
    "    # Define the internal K-Fold Stratified \n",
    "    internal_skf = StratifiedKFold(external_results_train, n_folds = n_internal_folds)\n",
    "    \n",
    "    # Iterate over several internal folds\n",
    "    for internal_train_index, internal_test_index in internal_skf:\n",
    "        \n",
    "        # Declare internal variables\n",
    "        internal_accuracy = 0\n",
    "        internal_gamma_value = 0\n",
    "        internal_c_value = 0\n",
    "        \n",
    "        # Split the internal training set and the internal test set \n",
    "        internal_params_train = external_params_train.iloc[internal_train_index, :]\n",
    "        internal_results_train = external_results_train[internal_train_index]\n",
    "        internal_params_test = external_params_train.iloc[internal_test_index, :]\n",
    "        internal_results_test = external_results_train[internal_test_index]\n",
    "        \n",
    "        # Iterate over gamma and C values to get best results in internal folds\n",
    "        for gamma_value in gamma_values_set:\n",
    "            for c_value in c_values_set:\n",
    "                \n",
    "                # Set up the internal classifier\n",
    "                internal_classifier = SVC(C = c_value, kernel = 'rbf', gamma = gamma_value)\n",
    "                internal_classifier.fit(internal_params_train, internal_results_train)\n",
    "                \n",
    "                # Getting the accuracy of the internal classifier for experimental\n",
    "                # values for gamma and C= 1/alpha\n",
    "                temporal_accuracy = internal_classifier.score(internal_params_test, internal_results_test)\n",
    "        \n",
    "                # Looking for the best internal accuracy\n",
    "                if temporal_accuracy > internal_accuracy:\n",
    "                    internal_accuracy = temporal_accuracy\n",
    "                    internal_gamma_value = gamma_value\n",
    "                    internal_c_value = c_value\n",
    "                    \n",
    "                    \n",
    "                # Looking for the best gamma and C values\n",
    "                if temporal_accuracy > best_accuracy:\n",
    "                    best_accuracy = temporal_accuracy\n",
    "                    optimal_gamma = gamma_value\n",
    "                    optimal_c = c_value\n",
    "        \n",
    "        # Compare and update the fold accuracy\n",
    "        if(internal_accuracy > external_accuracy):\n",
    "            external_accuracy = internal_accuracy\n",
    "            external_gamma_value = internal_gamma_value\n",
    "            external_c_value = internal_c_value\n",
    "            \n",
    "            \n",
    "    # Calculate the fold accuracy\n",
    "    external_classifier = SVC(C = external_c_value, kernel = 'rbf', gamma = external_gamma_value)\n",
    "    external_classifier.fit(external_params_train, external_results_train)\n",
    "    \n",
    "    fold_accuracy = external_classifier.score(external_params_test, external_results_test)\n",
    "    \n",
    "    # Perform a sum over the fold accuracy\n",
    "    final_accuracy = final_accuracy + fold_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obter a previsão da acurácia do SVM com kernel RBF neste conjunto de dados é preciso obter a média das acurácias dos folds externos, o que é feito no seguiente código: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide the final_accuracy over the number of folds to get the mean accuracy\n",
    "final_accuracy = final_accuracy/n_external_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "Finalmente são apresentados os resultados do nosso enfoque, mostrando a acurácia média do nosso SVM e os valores finais de gamma e C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média do SVM:  0.907716498694\n",
      "Valor final do gamma:  0.03125\n",
      "Valor final do C:  1\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print('Acurácia média do SVM: ', final_accuracy)\n",
    "print('Valor final do gamma: ', optimal_gamma)\n",
    "print('Valor final do C: ', optimal_c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
